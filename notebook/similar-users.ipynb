{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://100.64.13.143:4041\n",
       "SparkContext available as 'sc' (version = 2.4.1, master = local[*], app id = local-1556350981549)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n",
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.ml.feature._\n",
       "instacartFolderPath: String = instacart/\n",
       "bfpdFolderPath: String = bfpd/\n",
       "linkPath: String = insta-bfpd.csv\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(order_id,IntegerType,true), StructField(product_id,IntegerType,true))\n",
       "orders: org.apache.spark.sql.DataFrame = [order_id: string, user_id: string]\n",
       "order_products: org.apache.spark.sql.DataFrame = [order_id: int, product_id: int]\n",
       "orders_set: org.apache.spark.sql.DataFrame = [user_id: string, product_id: int]\n",
       "product_counts: org.apache.spark.sql.DataFrame = [user_id: string, product_id: int ... 1 more field]\n",
       "user_desc: org.apache.spark.rdd.RDD[(String, List[Int])] = MapPartitio..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.feature._\n",
    "\n",
    "val instacartFolderPath = \"instacart/\"\n",
    "val bfpdFolderPath = \"bfpd/\"\n",
    "val linkPath = \"insta-bfpd.csv\"\n",
    "\n",
    "val schema = StructType(\n",
    "    List(\n",
    "        StructField(\"order_id\", IntegerType),\n",
    "        StructField(\"product_id\", IntegerType)\n",
    "    )\n",
    ")\n",
    "\n",
    "val orders = spark.read.format(\"csv\").option(\"header\", \"true\").load(instacartFolderPath+\"orders.csv\").select(\"order_id\", \"user_id\")\n",
    "\n",
    "val order_products = spark.read.format(\"csv\").option(\"header\", \"true\").schema(schema).load(instacartFolderPath+\"order_*.csv\")\n",
    "\n",
    "val orders_set = orders.join(order_products, \"order_id\").drop(\"order_id\")\n",
    "\n",
    "val product_counts = orders_set.groupBy(\"user_id\", \"product_id\").count()\n",
    "\n",
    "val user_desc = product_counts.drop(\"count\").as[(String,Int)].rdd.groupByKey.mapValues( _.toList )\n",
    "\n",
    "val user_desc_vector = user_desc.map( row => (row._1, row._2.map(x => (x.toInt, 1.0)) ))\n",
    "\n",
    "val user_vector_df = user_desc_vector.map( row => (row._1, Vectors.sparse(49689, row._2))).toDF(\"user_id\", \"keys\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mh: org.apache.spark.ml.feature.MinHashLSH = mh-lsh_0b5db5dc7a01\n",
       "model: org.apache.spark.ml.feature.MinHashLSHModel = mh-lsh_0b5db5dc7a01\n",
       "splitDf: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([user_id: string, keys: vector], [user_id: string, keys: vector])\n",
       "usersA: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, keys: vector]\n",
       "usersB: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, keys: vector]\n",
       "transformedA: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, keys: vector ... 1 more field]\n",
       "transformedB: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [user_id: string, keys: vector ... 1 more field]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mh = new MinHashLSH()\n",
    "  .setNumHashTables(20)\n",
    "  .setInputCol(\"keys\")\n",
    "  .setOutputCol(\"values\")\n",
    "\n",
    "val model = mh.fit(user_vector_df)\n",
    "\n",
    "val splitDf = user_vector_df.randomSplit(Array(.995,.005))\n",
    "val (usersA,usersB) = (splitDf(0),splitDf(1))\n",
    "\n",
    "val transformedA = model.transform(usersA).cache()\n",
    "val transformedB = model.transform(usersB).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+\n",
      "|user_id|                keys|              values|           distCol|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "| 124168|(49689,[5077,1132...|[[1.16371862E8], ...|               0.0|\n",
      "| 200061|(49689,[4210,5077...|[[1.17743046E8], ...|0.8333333333333334|\n",
      "|  15270|(49689,[5077,4026...|[[1.472083947E9],...|0.8571428571428572|\n",
      "| 143048|(49689,[5077,1394...|[[5.69006954E8], ...|             0.875|\n",
      "|  61764|(49689,[5077,2390...|[[7.04531856E8], ...|             0.875|\n",
      "| 113711|(49689,[5077,6104...|[[3.80572922E8], ...|             0.875|\n",
      "| 201620|(49689,[5077,5782...|[[3.10958282E8], ...|0.8888888888888888|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "|user_id|                keys|              values|           distCol|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "|  90988|(49689,[5077,1467...|[[1.26784981E8], ...|0.9545454545454546|\n",
      "| 184777|(49689,[432,1090,...|[[3.5457512E7], [...|0.9545454545454546|\n",
      "|  64426|(49689,[424,2960,...|[[1.76951743E8], ...|0.9583333333333334|\n",
      "| 126343|(49689,[4605,4656...|[[3.94740651E8], ...|              0.96|\n",
      "|  48193|(49689,[1934,2541...|[[1.977142E7], [1...| 0.962962962962963|\n",
      "|  49504|(49689,[8501,8859...|[[4.8106878E7], [...|           0.96875|\n",
      "|  48294|(49689,[455,2656,...|[[1.2086317E7], [...| 0.972972972972973|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "key: org.apache.spark.ml.linalg.Vector = (49689,[5077,11323,14303,20082,22108,46522],[1.0,1.0,1.0,1.0,1.0,1.0])\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// println(user_vector_df.take(1)(0))\n",
    "val key = Vectors.sparse(49689, Array(5077,11323,14303,20082,22108,46522),Array(1.0,1.0,1.0,1.0,1.0,1.0))\n",
    "model.approxNearestNeighbors(transformedA, key, 7).show()\n",
    "model.approxNearestNeighbors(transformedB, key, 7).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+\n",
      "|user_id|                keys|              values|           distCol|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "| 124168|(49689,[5077,1132...|[[1.16371862E8], ...|0.5714285714285714|\n",
      "| 200061|(49689,[4210,5077...|[[1.17743046E8], ...|0.6666666666666667|\n",
      "| 137533|(49689,[4210],[1.0])|[[1.108687256E9],...|              0.75|\n",
      "| 146248|(49689,[4210],[1.0])|[[1.108687256E9],...|              0.75|\n",
      "|  15270|(49689,[5077,4026...|[[1.472083947E9],...|               0.8|\n",
      "| 164197|(49689,[4210,1152...|[[1.108687256E9],...|               0.8|\n",
      "|  44873|(49689,[4210,4273...|[[6.3132494E7], [...|               0.8|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "key2: org.apache.spark.ml.linalg.Vector = (49689,[4210,5077,22108,46522],[1.0,1.0,1.0,1.0])\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val key2 = Vectors.sparse(49689, Array(4210,5077,22108,46522),Array(1.0,1.0,1.0,1.0))\n",
    "model.approxNearestNeighbors(transformedA, key2, 7).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n",
      "|            datasetA|            datasetB|            distCol|\n",
      "+--------------------+--------------------+-------------------+\n",
      "|[49762, (49689,[1...|[111101, (49689,[...|                0.0|\n",
      "|[117980, (49689,[...|[130034, (49689,[...|0.33333333333333337|\n",
      "|[123997, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[37062, (49689,[1...|[111101, (49689,[...|                0.0|\n",
      "|[109672, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[99295, (49689,[1...|[111101, (49689,[...|                0.0|\n",
      "|[162586, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[66170, (49689,[1...|[111101, (49689,[...|                0.0|\n",
      "|[102792, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[163118, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[150279, (49689,[...|[111101, (49689,[...|                0.0|\n",
      "|[58530, (49689,[1...|[111101, (49689,[...|                0.0|\n",
      "+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.approxSimilarityJoin(transformedA, transformedB, 0.5).show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
